trainer: 'continuous_mlm'
args:
    seed: 0
    model_name: 'roberta-large'
    train: 'data/SuperFUGUE/CB/train.jsonl'
    dev: 'data/SuperFUGUE/CB/dev.jsonl'
    test: 'data/SuperFUGUE/CB/dev_all.jsonl'
    checklist: null
    template: '{premise} [P] {hypothesis}'
    label_map: '{"entailment": "yes", "contradiction": "no", "neutral": "maybe"}'
    initial_trigger: []
    label_field: 'label'
    add_padding: False
    preprocessor: null 
    evaluation_strategy: 'classification'
    decoding_strategy: null
    finetune_mode: []
    evaluation_metric: 'accuracy-macro-f1'
    linear: False
    skip_train: False
    skip_eval: False
    skip_test: False
    bsz: 2
    epochs: 30
    disable_dropout: False
    clip: 1.0
    limit: null
    reduction_factor: 16
    l1decay: 0.0
    theta: 1.0e32
    force_overwrite: True
    quiet: False
    tmp: True
    randomize_labels: True
    randomize_mask: False
    finetune_lr: null
parameters:
    accumulation_steps: [1, 2, 4]
    lr: [1.0e-5, 2.0e-5, 5.0e-5]
