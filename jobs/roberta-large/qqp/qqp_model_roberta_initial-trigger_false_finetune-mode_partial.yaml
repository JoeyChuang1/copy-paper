trainer: 'continuous_mlm'
args:
    seed: 0
    model_name: 'roberta-large'
    train: 'data/LittleGLUE/QQP/train.jsonl'
    dev: 'data/LittleGLUE/QQP/dev.jsonl'
    test: 'data/LittleGLUE/QQP/dev_all.jsonl'
    checklist: null
    template: '{question1} [T] {question2} [T] [P] [T] [T]'
    label_map: '{"0": "different", "1": "similar"}'
    initial_trigger: []
    label_field: 'label'
    add_padding: False
    preprocessor: null
    evaluation_strategy: 'classification'
    decoding_strategy: null
    finetune_mode:
        - 'trigger'
        - 'top-layer'
    evaluation_metric: 'accuracy-f1'
    linear: False
    skip_train: False
    skip_eval: False
    skip_test: False
    bsz: 2
    epochs: 30
    disable_dropout: False
    clip: 1.0
    limit: null
    reduction_factor: 16
    l1decay: 0.0
    theta: 1.0e32
    force_overwrite: True
    quiet: False
    tmp: True
parameters:
    accumulation_steps: [1, 2, 4]
    lr: [1.0e-5, 5.0e-5, 1.0e-4, 5.0e-4]
    finetune_lr: [1.0e-5, 5.0e-5, 1.0e-4, 5.0e-4]
